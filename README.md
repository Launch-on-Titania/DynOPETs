# DynOPETs: A Versatile Benchmark for Dynamic Object Pose Estimation and Tracking in Moving Camera Scenarios

---
<p align="center" style="font-size: larger;">
Xiangting Meng* · Jiaqi Yang* · Mingshu Chen · Chenxin Yan · Yujiao Shi · Wenchao Ding · Laurent Kneip
</p>
<p align="center" style="font-size: larger;">
* Equal Contribution
</p>

<p align="center" style="font-size: larger;">
  <a href="https://arxiv.org/pdf/2503.19625"><strong>Paper</strong></a> | 
  <a href="https://www.youtube.com/watch?v=hCOwqutWoLI"><strong>Video</strong></a> | 
  <a href="https://stay332.github.io/DynOPETs"><strong>Project Page</strong></a>
</p>
<p align="center">
  <img src="assets/demo.gif" alt="DynOPETs Demo GIF" width="70%">
</p>
🚧 Dataset coming soon! We are actively organizing and refining the data for public release. Stay tuned!

---
## 🖼️ Objects Overview

<p align="center">
  <img src="assets/cover.png" alt="DynOPETs Cover Image" width="60%">
</p>

---
## 🧩 Overview

**DynOPETs** DynOPETs is a real-world RGB-D dataset designed for object pose estimation and tracking in dynamic scenes with moving cameras.

### 📂 Dataset 

DynOPETs is split into two complementary subsets:
#### COPE-119
119 sequences covering 6 common categories from the COPE benchmark: bottles, bowls, cameras, cans, laptops, mugs.
Designed for COPE (Category-level Pose Estimation) methods.
#### UOPE-56
56 sequences of unconstrained household objects. Tailored for UOPE (Unseen Object Pose Estimation) methods.

---


## 🔧 Annotation Pipeline

<p align="center">
  <img src="assets/pipeline.png" alt="Annotation Pipeline" width="80%">
</p>

---

## 📦 Dataset (Coming Soon)

