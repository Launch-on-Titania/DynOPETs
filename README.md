# DynOPETs: A Versatile Benchmark for Dynamic Object Pose Estimation and Tracking in Moving Camera Scenarios

---
<p align="center" style="font-size: larger;">
Xiangting Meng* Â· Jiaqi Yang* Â· Mingshu Chen Â· Chenxin Yan Â· Yujiao Shi Â· Wenchao Ding Â· Laurent Kneip
</p>
<p align="center" style="font-size: larger;">
* Equal Contribution
</p>

<p align="center" style="font-size: larger;">
  <a href="https://arxiv.org/pdf/2503.19625"><strong>Paper</strong></a> | 
  <a href="https://www.youtube.com/watch?v=hCOwqutWoLI"><strong>Video</strong></a> | 
  <a href="https://stay332.github.io/DynOPETs"><strong>Project Page</strong></a>
</p>
<p align="center">
  <img src="assets/demo.gif" alt="DynOPETs Demo GIF" width="70%">
</p>
ğŸš§ Dataset coming soon! We are actively organizing and refining the data for public release. Stay tuned!

---
## ğŸ–¼ï¸ Objects Overview

<p align="center">
  <img src="assets/cover.png" alt="DynOPETs Cover Image" width="60%">
</p>

---
## ğŸ§© Overview

**DynOPETs** DynOPETs is a real-world RGB-D dataset designed for object pose estimation and tracking in dynamic scenes with moving cameras.

### ğŸ“‚ Dataset 

DynOPETs is split into two complementary subsets:
#### COPE-119
119 sequences covering 6 common categories from the COPE benchmark: bottles, bowls, cameras, cans, laptops, mugs.
Designed for COPE (Category-level Pose Estimation) methods.
#### UOPE-56
56 sequences of unconstrained household objects. Tailored for UOPE (Unseen Object Pose Estimation) methods.

---


## ğŸ”§ Annotation Pipeline

<p align="center">
  <img src="assets/pipeline.png" alt="Annotation Pipeline" width="80%">
</p>

---

## ğŸ“¦ Dataset (Coming Soon)

